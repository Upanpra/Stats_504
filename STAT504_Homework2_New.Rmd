---
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## STAT 504: Linear Regression
## Pratima K C

***Question 1a (1 point) Draw the scatterplot matrix of HT2, HT9, WT2, WT9, ST9 and BMI18. Compare the scatterplot matrix with the matrix of sample correlations for these variables. What do you observe? Compare the relationship of the predictors with the response and the pairwise predictor relationships. ***

***Answer: The scatter plot matrix and the matrix of sample correlations for the above variables both shows the similar results. The BMI18 has very low correlation with other metrics. The ST9 has higher correlation with HT9 than other metrics. However, the HT9 has higher correlation with HT2 than ST9 because the height at age 9 is mostly likely to be realted with height at age 2 than strength at age 9. Similarly, the WT9 has higher correlation with HT9 than other metrices. The scatter polot and correaltions of these metrics are given below:***

```{r, include=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
library(alr4)
#head(BGSgirls)
#summary(BGSgirls)
pairs(~HT2 + HT9 + WT2 +  WT9 +  ST9 + BMI18  , data=BGSgirls , main="Scatter Plot")

print("Correlation of different metrices")
print(cor(BGSgirls[,c(1,2,3,4,6,11)]), 3)

```

***Question 1 b (2 points) Fit two linear models:***

***1. E[BMI18 | WT9, ST9]*** 

***2. E[BMI18 | HT2, WT2, HT9, WT9, ST9]***

***Print their summaries and comment on the output. Which of the estimates that are in model 2 and not model 1 are significant at the 5% level ($\alpha$ = 0:05)?***

***Answer: In model 1 both the predictor variables (WT9 & ST9) are significant as p-values are smaller than alpha=0.05. However, in model 2 three predictor varilabes (HT2, WT2, HT9)are not significant as their p-values are larger than $\alpha$=0.05. But other two variables (WT9 & ST9) both variables are significant for model 2 too. When comapring non of the estimates that are in model 2 and not in model 1 are significant. The summary for both models are given below:***

```{r, include=TRUE, echo=FALSE}
model1= lm(formula = BMI18 ~ WT9+ST9, data=BGSgirls)
summary(model1)

model2=lm(formula = BMI18 ~ HT2+WT2+ HT9+ WT9+ ST9, data=BGSgirls)
summary(model2)
```

***Question 1c (4 points) Conduct an anova comparison of the above 2 models.Test the hypothesis H0 : ($\beta$HT2; $\beta$WT2; $\beta$HT9) = (0; 0; 0) at the 5% level.***

***Answer:***

```{r, include=TRUE, echo=FALSE}
anova(model1, model2)

```

***Question 1c (i)(1 point) What is the test statitic for this test?***

***Answer: The test statistics for this test is 2.7421***

***Question 1c (ii)(1 point) What distribution does this test statistic follow under the null hypothesis (specity the degrees of freedom)***

***Answer: RSS(model1 & model2) and df, here test statistic follow under 64 & 3.***

***Question 1c (iii) (1 point) Do you reject the null hypothesis?***

***Answer: No, we cannot reject the null hypothesis because the p-value is higher than significance level at $\alpha=0.05$.***

***Question 1c (iv) (1 point) Based on the result of the hypothesis test, which model would you choose?***

***Answer: I would choose to use the smaller model (model1) as we cannot reject the null hypothesis in bigger model (model2).***

***Question 1d (2 point) Plot the histogram of the residuals and the TA plot from the model 2 above. Do the normality and the constant variance assumptions appear to hold?***

***Answer: The histogram seems to be right skewed so it does not holds the normality assumption. The TA plots shows that data mostly have the connstant variable through out but it gets spreaded towards the right side with higher fitted values and this side have higher variance. Therefore the constant variance assumptions to be voilated slightly. ***

```{r, include=TRUE, echo=FALSE}
par(mfrow=c(1,2))
hist(model2$residuals, main="Histogram of Residuals")
plot(model2, which =1)
```


***Question 1e (2 point) What are the $\hat{\sigma}$ and the in-sample MSE of model 2 above?***

***Answer: For $\hat\sigma$ I used the following equation:***
$\hat\sigma=\sqrt(RSS/(n-p+1))$ 

***$\hat\sigma=2.139801$ and $MSE= RSS/n= 293.04/70= 4.186286$***

***Question 1f (5 point) Consider model 2 summary output and test null hypotheses***

***Answer: Different correction are given below:***
```{r, include=TRUE, echo=FALSE}

print('p-values of model2')
p.vals <- summary(model2)$coefficients[2:6,4]
print(p.vals)

print("Bonferroni Correction")
p.bonf <- p.adjust(p.vals, method="bonferroni")
#print(p.bonf)
print("Parameters where p-value < 0.1")
p.bonf < 0.1
```
***Therefore, we only reject $H_{0}^{4}$ because it has p-value <0.1 ***

***Holm correction***

```{r, include=TRUE, echo=FALSE}
holm_p_val <- 0.1 / c(5, 4,3, 2, 1)
#holm_p_val
print("Parameters where p-value < adjusted significant level")
sort(p.vals) < holm_p_val

```

***Therefore, we only reject $H_{0}^{4}$ because it has p-value < $\alpha$ ***

***Benjamini-Hochberg correction***

```{r, include=TRUE, echo=FALSE}
#print("The following code is for Benjamini-Hochberg correction")
fdr <- 0.1/3*c(1,2,3,4,5)
#fdr

print("Parameters where p-value < adjusted significant level")
sort(p.vals) < fdr

p.adjust.fdr <- p.adjust(p.vals, method = "fdr")
#print(p.adjust.fdr)

```

***Therefore, we only reject $H_{0}^{4}$ because it has p-value < $\alpha$ ***


***Question 2 a (1 point) Consider the regression of HT18 (response) on HT9 and Sex (predictors). Draw the scatterplot of HT18 vs HT9 using a different symbol or color for men and women (with a legend). Comment on the appropriate mean function for the data. Looking at the scatterplot, do you think including the factor Sex in the linear model is justified? Explain. ***

***Answer: Yes, I think including the factor Sex in the linear model is jusitifies as we can see the scatter plot, it seems to have two linear model. As per the graph male tend to be taller than female in both age group.  The mean function is given by $E[Y|X=x]=\beta_0+ \beta_1*X_{HT9}+ \beta_2*X_{Sex}$, where $\beta_0$ is expected value of y (HT18), when HT9=0, and Sex=0 that mean male. ***


```{r, include=TRUE, echo=FALSE}
plot(HT18~HT9,data=BGSall,col=ifelse(BGSall$Sex==1, "blue", "red"), pch=ifelse(BGSall$Sex==1, 20, 8))
legend("topright", col=c("red", "blue"), legend = c("Male", "Female"), pch=c(8,20))

#plot(formula=HT18~ HT9, data=BGSall, col=ifelse(BGSall$Sex==1, "red", "blue"), pch=20)
#legend("bottomright", legend =c("Female", "Male"), bty = "n", cex = 1.2, col = c("red", "blue"), pch =20)
```

***Question 2b (6 points) Fit the linear model (call it fit.height) with HT18 as a response and HT9 and Sex as predictors.***

***Answer:***
```{r, include=TRUE, echo=FALSE}
fit.height=lm(formula = HT18~HT9+as.factor(Sex), data=BGSall)
summary(fit.height)
#BGSall.data=BGSall()
#BGSall.data1= BGSall[which(BGSall$Sex %in% c(1,0)),]
#BGSall.data1$Sex= as.factor(as.numeric(BGSall.data1$Sex)+1)

#fit.height=lm(formula = HT18 ~ HT9+Sex, data=BGSall.data1)
#summary(fit.height)
#summary(fit.height1)
```
***Question 2b (i) (1 point) Consider the fitted regression line for women. What is the intercept of this fitted line?***

***Answer: The intercept of this fitted line is 48.51731+ (-11.69584)= 36.82147***

***Question 2b (ii) (1 point) What is the predicted height at 18 years of age for a 135cm tall 9-year-old girl (heights given in the data set are in centimeters - cm)?***

***Answer: The predicted height at 18 years of age for a 135 cm tall 9-year old girl is 166.4291 cm ***
```{r, include=TRUE, echo=FALSE}
predict(fit.height, data.frame(Sex=as.factor(1), HT9=c(135)))
#predict(fit.cars1,data.frame(cylinders=as.factor(0),weight=c(3000)))
```

***Question 2b (iii) (2 points) What would be the predicted average change in height at age 18, for the same girl if in fact her height at age 9 was 137cm, but was measured wrongly as 135cm?***

***Answer: The predicted average change in height at age 18 would be: (137-135)*0.96006= 1.92012cm***

```{r, include=TRUE, echo=FALSE}
predicted_change= (137-135)*0.96006
```

***Question 2b (iv) (1 point) Based on this model, what is the 95% confidence interval for the difference in height between men and women? ***

***Answer: Based on this model the 95% confidence interval for the difference in the height between men and women is:***

$=-11.69584\pm (0.59036*1.96)$

$=-11.69584\pm 1.157106$

$=(-12.8524, -10.5396)$ 


***Question 2b (v) (1 point) Was your suspicion from part (a) correct? Test the hypothesis H0 : $\beta$ Sex = 0 at the 5% level. Do you reject the null hypothesis? Explain. ***

***Answer: The null hypothesis is rejected as the p-value (2e-16) is < 0.05. The suspicion from part a is correct. The inclusion of sex does make difference in the model. ***

***Question 2c (5.5 + 4 Bonus points) Consider the following three models in addition to the above model in fit.height. (These are written in Wilkinson-Rogers notation, 1 indicates that the intercept is present in the model.) 1. HT18 | 1 + HT2 + HT9 + Sex 2. HT18 | 1 + HT2 + HT9 + Sex + Sex:HT2 + Sex:HT9 3. HT18 | 1 + HT2 + HT9 + HT2:HT9 + Sex + Sex:HT2 + Sex:HT9 + Sex:HT2:HT9***

***Answer:***
```{r, include=TRUE, echo=FALSE}
fit.height2=lm(formula = HT18~HT2+HT9+Sex, data=BGSall)
fit.height3=lm(formula = HT18~HT2+HT9+Sex+Sex:HT2+Sex:HT9, data=BGSall)
fit.height4=lm(formula = HT18~HT2+HT9+HT2:HT9+Sex+Sex:HT2+Sex:HT9+Sex:HT2:HT9, data=BGSall)
summary(fit.height2)
summary(fit.height3)
summary(fit.height4)

```
***Question 2c(i) (2 points) How many parameters are estimated in each of the proposed models (fit.height,fit.height2, fit.height3, fit.height4)?***

***Answer: The number of parameter estimated in each modele are: fit.height= 3; fit.height2= 4; fit.height3= 6; fit.height4= 8***

***Question 2c (ii) (1.5 points) What is the predicted average height of a girl who is 135cm tall at age 9 and 90cm tall at age 2 accoriding to fit.height2, fit.height3, and fit.height4 respectively?***

***Answer: The prediction is given below:***

```{r, include=TRUE, echo=FALSE}
print("Prediction for fit.heighth2")
predict(fit.height2, data.frame(Sex=1, HT9=c(135), HT2=c(90)))
print("Prediction for fit.heighth3")
predict(fit.height3, data.frame(Sex=1, HT9=c(135), HT2=c(90)))
print("Prediction for fit.heighth4")
predict(fit.height4, data.frame(Sex=1, HT9=c(135), HT2=c(90)))

```

***Question 2c(iii) (Bonus 2 points) Consider a sequential procedure where you start from the smallest model (fit.height) and compare it with model fit.height2 using the anova test at the 10% level. If model fit.height is not rejected the procedure ends and you opt for model fit.height as the preferred model.***

***Answer: When comparing the smaller model (fit.height) with the larger model (fit.height2) we cannot reject the null hypothesis as the p-value (0.7394) > 0.1. So opt to choose the smaller model (fit.height). ***
```{r, include=TRUE, echo=FALSE}
anova(fit.height,fit.height2)
#anova(fit.height2, fit.height3)
#anova(fit.height3, fit.height4)

```

***Question 2c(iv) (Bonus 2 points) Consider a converse sequential procedure from above. You start with largest model (from fit.height4) and compare it with model fit.height3 using the anova test at the 10% level. If the p-value is smaller than 10% you opt for the bigger model.***

***Answer: When comparing the largest model (fit.height4) iwth the another model (fit.height3) we cannot reject the null hypothesis as the p-value (0.7465) > 0.1. Then, we compared the model fit.height3 with fit.height2, here we reject the null hypothesis because p-value (0.05412) < 0.1. Therefore we opt to choose the larger model ie. fit.heigth3.***

```{r, include=TRUE, echo=FALSE}
anova(fit.height3, fit.height4)
anova(fit.height2, fit.height3)
#anova(fit.height,fit.height2)

```

***Question 2c(v) (2 points) What is the $\hat\sigma$ associated with models fit.height, fit.height2, fit.height3 and fit.height4? Based on the $\hat\sigma$, what is your preferred model?***

***Answer: Based on $\hat\sigma$ I would prefer the fit.height3 because it has smallest $\hat\sigma$ value. ***

***fit.height($\hat\sigma$)=  3.432 ***

***fit.height2($\hat\sigma$)= 3.444***

***fit.height3($\hat\sigma$)= 3.393***

***fit.height4($\hat\sigma$)= 3.412***

